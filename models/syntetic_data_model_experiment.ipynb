{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd31d252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import warnings\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from fairness_methods.methods import FairnessMethods\n",
    "from models.basic_mf_model import BasicMatrixFactorization\n",
    "from utils.data_generator import *\n",
    "from utils.metrics import RecommendationSystemMetrics\n",
    "from utils.util import *\n",
    "from utils.tuning import *\n",
    "\n",
    "from models.nn_fairness_model import run_nn_fairness_model\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85dec41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_id_to_group(df):\n",
    "    \"\"\"\n",
    "    split movie id into groups types like genres\n",
    "    :param df: input data\n",
    "    :return: dict with movie_id as key group id as value\n",
    "    \"\"\"\n",
    "    movie_id_to_index = {movie_id: index for (index, movie_id) in enumerate(df['movie_id'].unique())}\n",
    "    movie_id_to_group = {}\n",
    "    for row in df[[\"movie_id\"] + GENRES].to_dict('records'):\n",
    "        # set genres group by women ratings and men ratings as wrote in the paper\n",
    "        # \"Women and men both score action, crime, and sci-fi films about equally, but men rate these film much more frequently\"\n",
    "        is_woman_group = 1 if sum([row[genre] for genre in WOMEN_GENRES]) > 0 else 0\n",
    "        movie_id_to_group[movie_id_to_index[row['movie_id']]] = is_woman_group\n",
    "\n",
    "    return movie_id_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9456ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_ids_by_gender(df):\n",
    "    \"\"\"\n",
    "    split the input users to groups by gender\n",
    "    :param df: input data\n",
    "    :return: user_gender: gender to list of user ids, user_id_to_group: dict of user ids to group id\n",
    "    \"\"\"\n",
    "    user_id_to_index = {user_id: index for (index, user_id) in enumerate(df['user_id'].unique())}\n",
    "    user_gender = {}\n",
    "    user_id_to_group = {}\n",
    "    for row in df[[\"user_id\", \"gender\"]].to_dict('records'):\n",
    "        user_gender.setdefault(row['gender'], []).append(user_id_to_index[row['user_id']])\n",
    "        user_id_to_group[user_id_to_index[row['user_id']]] = 1 if row['gender'] == \"F\" else 0\n",
    "    user_gender[\"F\"] = list(set(user_gender[\"F\"]))\n",
    "    user_gender[\"M\"] = list(set(user_gender[\"M\"]))\n",
    "    return user_gender, user_id_to_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce065c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(tmp_df, zero_matrix, columns=\"movie_id\", test_ratio=0.2, movie_len=True):\n",
    "    \"\"\"\n",
    "    preprocess before training. split into train and test, fill empty values with zero matrix, add missing items and convert it to matrix\n",
    "    :param tmp_df: input data\n",
    "    :param zero_matrix: output matrix shape with zero values\n",
    "    :param columns: column name\n",
    "    :param test_ratio: percentage of test data\n",
    "    :param movie_len: is it movie_len dataset or synthetic dataset\n",
    "    :return: train_df, test_df, tmp_user_gender: gender to list of user ids, tmp_user_id_to_group: dict of user ids to group id dict with movie_id as key group id as value\n",
    "    \"\"\"\n",
    "    tmp_train, tmp_test = train_test_split(tmp_df, test_size=test_ratio, shuffle=True, stratify=tmp_df[[\"user_id\"]])\n",
    "#     tmp_train, tmp_test = train_test_split(tmp_df, test_size=test_ratio, shuffle=True)\n",
    "\n",
    "    tmp_train = tmp_train[tmp_train[columns].isin(tmp_test[columns].unique())]\n",
    "    tmp_user_gender, tmp_user_id_to_group = get_user_ids_by_gender(tmp_df)\n",
    "    item_to_group = get_item_id_to_group(tmp_df) if movie_len else {}\n",
    "    tmp_train_set = normalize_train_test_matrix(columns, tmp_train, zero_matrix)\n",
    "    tmp_test_set = normalize_train_test_matrix(columns, tmp_test, zero_matrix)\n",
    "    tmp_test_set = tmp_test_set.replace(0, np.nan)\n",
    "    print(\"train_set shape: \", tmp_train_set.shape, \" test_set shape: \", tmp_test_set.shape)\n",
    "    return tmp_train_set, tmp_test_set.to_numpy(), tmp_user_gender, tmp_user_id_to_group, item_to_group\n",
    "\n",
    "\n",
    "def normalize_train_test_matrix(columns, tmp_split_df, zero_matrix):\n",
    "    print(\"start normalization\")\n",
    "    tmp_set = pd.pivot_table(tmp_split_df, values='rating', index='user_id', columns=columns)\n",
    "    tmp_set = (tmp_set-tmp_set.min())/(tmp_set.max()-tmp_set.min())\n",
    "    for source_matrix_column in zero_matrix.columns:\n",
    "        if source_matrix_column not in tmp_set.columns:\n",
    "            tmp_set[source_matrix_column] = 0\n",
    "    tmp_set = tmp_set[zero_matrix.columns]\n",
    "    tmp_set.columns = range(tmp_set.shape[1])\n",
    "    tmp_set.fillna(0, inplace=True)\n",
    "    print(\"finished normalization\")\n",
    "    return tmp_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd5f80",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a824d5c9",
   "metadata": {},
   "source": [
    "# generate_synthetic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1830215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************rating probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.8 │    0.2 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.8 │    0.8 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.2 │    0.8 │    0.8 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.2 │    0.2 │    0.8 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************observation probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.4 │    0.4 │    0.4 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************rating probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.8 │    0.2 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.8 │    0.8 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.2 │    0.8 │    0.8 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.2 │    0.2 │    0.8 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************observation probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │  0.6  │    0.2 │   0.1  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │  0.3  │    0.4 │   0.2  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │  0.1  │    0.3 │   0.5  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │  0.05 │    0.5 │   0.35 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************rating probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.8 │    0.2 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.8 │    0.8 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.2 │    0.8 │    0.8 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.2 │    0.2 │    0.8 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************observation probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.4 │    0.4 │    0.4 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.4 │    0.4 │    0.4 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************rating probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │   0.8 │    0.2 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │   0.8 │    0.8 │    0.2 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │   0.2 │    0.8 │    0.8 │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │   0.2 │    0.2 │    0.8 │\n",
      "╘════╧═══════╧════════╧════════╛\n",
      "****************************observation probability****************************\n",
      "\n",
      "╒════╤═══════╤════════╤════════╕\n",
      "│    │   Fem │   STEM │   Masc │\n",
      "╞════╪═══════╪════════╪════════╡\n",
      "│ W  │  0.6  │    0.2 │   0.1  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ WS │  0.3  │    0.4 │   0.2  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ M  │  0.1  │    0.3 │   0.5  │\n",
      "├────┼───────┼────────┼────────┤\n",
      "│ MS │  0.05 │    0.5 │   0.35 │\n",
      "╘════╧═══════╧════════╧════════╛\n"
     ]
    }
   ],
   "source": [
    "# uniform user groups and uniform observation probabilities (U)\n",
    "U_ratings, U_item_id_to_group = generate_synthetic_data(observation_model='uniform', user_distribution='uniform')\n",
    "# uniform user groups and biased observation probabilities (O)\n",
    "O_ratings, O_item_id_to_group = generate_synthetic_data(observation_model='unbalanced', user_distribution='uniform')\n",
    "# biased user groups and uniform observation probabilities (P)\n",
    "P_ratings, P_item_id_to_group = generate_synthetic_data(observation_model='uniform', user_distribution='imbalanced')\n",
    "# biased user groups and biased observation probabilities (OP)\n",
    "OP_ratings, OP_item_id_to_group = generate_synthetic_data(observation_model='unbalanced', user_distribution='imbalanced')\n",
    "\n",
    "synthetic_tests_df = {\"U\": U_ratings, \"O\": O_ratings, \"P\": P_ratings, \"OP\": OP_ratings}\n",
    "synthetic_tests_item_groups = {\"U\": U_item_id_to_group, \"O\": O_item_id_to_group, \"P\": P_item_id_to_group,\n",
    "                               \"OP\": OP_item_id_to_group}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "538b4dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# html_path = 'exp_results.html'\n",
    "# zero_synthetic_matrix = np.full((NUM_USERS, NUM_ITEMS), 0)\n",
    "# zero_synthetic_matrix = pd.DataFrame(zero_synthetic_matrix)\n",
    "# res_all = pd.DataFrame()\n",
    "# res_all_val = pd.DataFrame()\n",
    "\n",
    "# for test_name, tmp_df_ratings in synthetic_tests_df.items():\n",
    "#     res_per_test ={}\n",
    "#     res_per_test_val ={}\n",
    "#     for metric in ['val_score', 'abs_score', 'over_score', 'under_score', 'under_score', 'non_parity_score',None]:\n",
    "#         train_set, test_set, tmp_user_gender, tmp_user_id_to_group, _ = preprocessing(tmp_df_ratings,zero_synthetic_matrix, columns=\"item_id\",movie_len=False)\n",
    "#         trainig_dict= run_nn_fairness_model('gmf',train_set,test_set,metric = metric,num_epochs=30, num_users=train_set.shape[0], num_items=train_set.shape[1], embed_dim=8,\n",
    "#                               dis_group=tmp_user_gender['F'], adv_group=tmp_user_gender['M'], lr=0.1,layers=[64,32,16,8], early_stop=0.00000001,unfairness_reg=0.5,early_stop_tol=3)\n",
    "        \n",
    "#         res_per_test[metric] = trainig_dict['train_dict_unfair']\n",
    "#         res_per_test_val[metric] =trainig_dict['val_dict_unfair']\n",
    "#         print(f'done {metric}')\n",
    "#     print(f'done {test_name}')\n",
    "#     res_per_test = pd.DataFrame.from_dict(res_per_test)\n",
    "#     res_per_test_val = pd.DataFrame.from_dict(res_per_test_val)\n",
    "\n",
    "#     res_per_test['test'] = test_name\n",
    "#     res_per_test_val['test'] = test_name\n",
    "\n",
    "#     res_all = pd.concat([res_all,res_per_test], axis=0)\n",
    "#     res_all_val = pd.concat([res_all_val,res_per_test_val], axis=0)\n",
    "\n",
    "#     res_all.to_csv('res_gmf_30e.csv')\n",
    "#     res_all_val.to_csv('res_gmf_30e_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb36c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "start normalization\n",
      "finished normalization\n",
      "start normalization\n",
      "finished normalization\n",
      "train_set shape:  (400, 300)  test_set shape:  (400, 300)\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " user_id (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " item_id (InputLayer)           [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 8)            3200        ['user_id[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 8)            2400        ['item_id[0][0]']                \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 8)            0           ['embedding_2[0][0]',            \n",
      "                                                                  'embedding_3[0][0]']            \n",
      "                                                                                                  \n",
      " prediction (Dense)             (None, 1)            9           ['multiply_1[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5,609\n",
      "Trainable params: 5,609\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 0, Loss: 0.5947461128234863\n",
      "Epoch 1, Loss: 0.49522900581359863\n"
     ]
    }
   ],
   "source": [
    "zero_synthetic_matrix = np.full((NUM_USERS, NUM_ITEMS), 0)\n",
    "zero_synthetic_matrix = pd.DataFrame(zero_synthetic_matrix)\n",
    "tuning_all = pd.DataFrame()\n",
    "tuning_all_val = pd.DataFrame()\n",
    "for i in range(50):\n",
    "    print(i)\n",
    "    res_all = pd.DataFrame()\n",
    "    res_all_val = pd.DataFrame()\n",
    "    for test_name, tmp_df_ratings in synthetic_tests_df.items():\n",
    "        hp= get_random_hp_choises()\n",
    "        res_per_test ={}\n",
    "        res_per_test_val ={}\n",
    "        for metric in ['val_score', 'abs_score', 'over_score', 'under_score', 'under_score', 'non_parity_score',None]:\n",
    "            train_set, test_set, tmp_user_gender, tmp_user_id_to_group, _ = preprocessing(tmp_df_ratings,zero_synthetic_matrix, columns=\"item_id\",movie_len=False)\n",
    "            trainig_dict= run_nn_fairness_model('gmf',train_set,test_set,metric = metric,num_epochs=2, num_users=train_set.shape[0], num_items=train_set.shape[1], embed_dim=8,\n",
    "                                  dis_group=tmp_user_gender['F'], adv_group=tmp_user_gender['M'], lr=hp['lr'],layers=[64,32,16,8], early_stop=hp['early_stop'],unfairness_reg=hp['unfairness_reg'],early_stop_tol=3)\n",
    "\n",
    "            res_per_test['model'] = hp['model']\n",
    "            res_per_test_val['model'] = hp['model']\n",
    "\n",
    "            res_per_test['early_stop'] = hp['early_stop']\n",
    "            res_per_test_val['early_stop'] = hp['early_stop']\n",
    "            \n",
    "            res_per_test['unfairness_reg'] = hp['unfairness_reg']\n",
    "            res_per_test_val['unfairness_reg'] = hp['unfairness_reg']\n",
    "\n",
    "            res_per_test['lr'] = hp['lr']\n",
    "            res_per_test_val['lr'] = hp['lr']\n",
    "\n",
    "\n",
    "            res_per_test[metric] = trainig_dict['train_dict_unfair']\n",
    "            res_per_test_val[metric] =trainig_dict['val_dict_unfair']\n",
    "            print(f'done {metric}')\n",
    "        print(f'done {test_name}')\n",
    "        res_per_test = pd.DataFrame.from_dict(res_per_test)\n",
    "        res_per_test_val = pd.DataFrame.from_dict(res_per_test_val)\n",
    "\n",
    "        res_per_test['test'] = test_name\n",
    "        res_per_test_val['test'] = test_name\n",
    "\n",
    "        res_all = pd.concat([res_all,res_per_test], axis=0)\n",
    "        res_all_val = pd.concat([res_all_val,res_per_test_val], axis=0)\n",
    "        \n",
    "    tuning_all = pd.concat([tuning_all,res_all], axis=0)\n",
    "    tuning_all_val = pd.concat([res_all_val,tuning_all_val], axis=0)\n",
    "    tuning_all.to_csv('tuning_syn.csv')\n",
    "    tuning_all_val.to_csv('tuning_syn_val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2989c88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
